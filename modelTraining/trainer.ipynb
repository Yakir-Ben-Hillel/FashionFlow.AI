{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.16.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, TensorBoard\n",
    "import time\n",
    "# Display the version of TensorFlow\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "base_path = 'C:\\\\Dev'\n",
    "csv_file = os.path.join(base_path, 'OneHotEncoderDataframe.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [ItemId, PrimaryHierarchyId, Volume, ColorId, PlpTagId, SiteRulerId, UnitsOfMeasurmentId, IsUnisex, Ingredients, HierarchyId, AudienceId, ProductTypeId, ProgrammaId, CategoryId, FitId, FitTableType, TagTypeId, IsTagMan, IsTagWoman, IsTagKids, CustomTagId, ImageType, ImageFileName, ImagePath, AudienceId_1.0, AudienceId_2.0, AudienceId_3.0, AudienceId_nan, ProductTypeId_3.0, ProductTypeId_4.0, ProductTypeId_5.0, ProductTypeId_6.0, ProductTypeId_7.0, ProductTypeId_9.0, ProductTypeId_10.0, ProductTypeId_16.0, ProductTypeId_17.0, ProductTypeId_18.0, ProductTypeId_19.0, ProductTypeId_20.0, ProductTypeId_22.0, ProductTypeId_23.0, ProductTypeId_28.0, ProductTypeId_29.0, ProductTypeId_30.0, ProductTypeId_31.0, ProductTypeId_32.0, ProductTypeId_33.0, ProductTypeId_34.0, ProductTypeId_35.0, ProductTypeId_36.0, ProductTypeId_39.0, ProductTypeId_nan, ProgrammaId_12.0, ProgrammaId_13.0, ProgrammaId_14.0, ProgrammaId_15.0, ProgrammaId_16.0, ProgrammaId_17.0, ProgrammaId_18.0, ProgrammaId_19.0, ProgrammaId_20.0, ProgrammaId_21.0, ProgrammaId_22.0, ProgrammaId_23.0, ProgrammaId_24.0, ProgrammaId_25.0, ProgrammaId_26.0, ProgrammaId_27.0, ProgrammaId_28.0, ProgrammaId_29.0, ProgrammaId_30.0, ProgrammaId_31.0, ProgrammaId_32.0, ProgrammaId_33.0, ProgrammaId_34.0, ProgrammaId_35.0, ProgrammaId_36.0, ProgrammaId_37.0, ProgrammaId_38.0, ProgrammaId_39.0, ProgrammaId_40.0, ProgrammaId_41.0, ProgrammaId_42.0, ProgrammaId_43.0, ProgrammaId_44.0, ProgrammaId_45.0, ProgrammaId_46.0, ProgrammaId_47.0, ProgrammaId_48.0, ProgrammaId_49.0, ProgrammaId_50.0, ProgrammaId_52.0, ProgrammaId_53.0, ProgrammaId_54.0, ProgrammaId_55.0, ProgrammaId_57.0, ProgrammaId_58.0, ProgrammaId_65.0, ProgrammaId_66.0, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 741 columns]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "All values in column x_col=ImagePath must be strings.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 67\u001b[0m\n\u001b[0;32m     64\u001b[0m train_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([pd\u001b[38;5;241m.\u001b[39mSeries(train_paths, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImagePath\u001b[39m\u001b[38;5;124m'\u001b[39m), train_labels_df], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     65\u001b[0m val_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([pd\u001b[38;5;241m.\u001b[39mSeries(val_paths, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImagePath\u001b[39m\u001b[38;5;124m'\u001b[39m), val_labels_df], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 67\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_datagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow_from_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# The root directory containing all subdirectories\u001b[39;49;00m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mImagePath\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_labels_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Resize images to 128x128\u001b[39;49;00m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mraw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m     75\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m val_generator \u001b[38;5;241m=\u001b[39m val_datagen\u001b[38;5;241m.\u001b[39mflow_from_dataframe(\n\u001b[0;32m     78\u001b[0m     dataframe\u001b[38;5;241m=\u001b[39mval_df,\n\u001b[0;32m     79\u001b[0m     directory\u001b[38;5;241m=\u001b[39mimage_directory,  \u001b[38;5;66;03m# The root directory containing all subdirectories\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     84\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     85\u001b[0m )\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Optional: Save the processed data\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1208\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_dataframe\u001b[1;34m(self, dataframe, directory, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, subset, interpolation, validate_filenames, **kwargs)\u001b[0m\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_duplicates\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m   1202\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1203\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_duplicates is deprecated, you can drop duplicates \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1204\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby using the pandas.DataFrame.drop_duplicates method.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1205\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[0;32m   1206\u001b[0m     )\n\u001b[1;32m-> 1208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1211\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1213\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_filenames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_filenames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1230\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:751\u001b[0m, in \u001b[0;36mDataFrameIterator.__init__\u001b[1;34m(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, keep_aspect_ratio, dtype, validate_filenames)\u001b[0m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m=\u001b[39m dtype\n\u001b[0;32m    750\u001b[0m \u001b[38;5;66;03m# check that inputs match the required class_mode\u001b[39;00m\n\u001b[1;32m--> 751\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    753\u001b[0m     validate_filenames\n\u001b[0;32m    754\u001b[0m ):  \u001b[38;5;66;03m# check which image files are valid and keep them\u001b[39;00m\n\u001b[0;32m    755\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filter_valid_filepaths(df, x_col)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:813\u001b[0m, in \u001b[0;36mDataFrameIterator._check_params\u001b[1;34m(self, df, x_col, y_col, weight_col, classes)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;66;03m# check that filenames/filepaths column values are all strings\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(df[x_col]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m))):\n\u001b[1;32m--> 813\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    814\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll values in column x_col=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    815\u001b[0m     )\n\u001b[0;32m    816\u001b[0m \u001b[38;5;66;03m# check labels are string if class_mode is binary or sparse\u001b[39;00m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_mode \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n",
      "\u001b[1;31mTypeError\u001b[0m: All values in column x_col=ImagePath must be strings."
     ]
    }
   ],
   "source": [
    "# Step 2: Load and Preprocess Data in Chunks\n",
    "image_directory = os.path.join(base_path, 'images_binary')\n",
    "training_path = os.path.join(base_path, 'training_data')\n",
    "#ItemId,PrimaryHierarchyId,Volume,ColorId,PlpTagId,SiteRulerId,UnitsOfMeasurmentId,IsUnisex,Ingredients,HierarchyId,AudienceId,ProductTypeId,ProgrammaId,CategoryId,FitId,FitTableType,TagTypeId,IsTagMan,IsTagWoman,IsTagKids,CustomTagId,ImageType,ImageFileName,ImagePath\n",
    "# Create a function to read the CSV in chunks and process the data\n",
    "def process_csv_in_chunks(csv_file, chunk_size=10000):\n",
    "    # Read the first chunk to determine column names and dtypes\n",
    "    first_chunk = pd.read_csv(csv_file, nrows=1)\n",
    "    column_names = first_chunk.columns\n",
    "    # Assume all columns except the last two are numeric, and the last two columns are strings\n",
    "    dtypes = {col: np.float32 for col in column_names}\n",
    "    dtypes[column_names[22]] = str  # 'imageName'\n",
    "    dtypes[column_names[23]] = str  # 'ImagePath'\n",
    "\n",
    "    for chunk in pd.read_csv(csv_file, chunksize=chunk_size, dtype=dtypes):\n",
    "        yield chunk\n",
    "\n",
    "# Use the generator to process the CSV in chunks and split into training and validation sets incrementally\n",
    "def incremental_train_val_split(generator, test_size=0.2, random_state=42):\n",
    "    train_data_list = []\n",
    "    val_data_list = []\n",
    "    for chunk in generator:\n",
    "        # Fill missing values in 'ImagePath' with a placeholder string\n",
    "        chunk['ImageFileName'] = chunk['ImageFileName'].fillna('placeholder.jpg')\n",
    "        chunk['ImagePath'] = chunk['ImagePath'].fillna('placeholder.jpg')\n",
    "        \n",
    "        # Ensure all values in 'ImageFileName' and 'ImagePath' are strings\n",
    "        chunk['ImageFileName'] = chunk['ImageFileName'].astype(str)\n",
    "        chunk['ImagePath'] = chunk['ImagePath'].astype(str)\n",
    "\n",
    "        train_chunk, val_chunk = train_test_split(chunk, test_size=test_size, random_state=random_state)\n",
    "        train_data_list.append(train_chunk)\n",
    "        val_data_list.append(val_chunk)\n",
    "    train_data = pd.concat(train_data_list)\n",
    "    val_data = pd.concat(val_data_list)\n",
    "    empty_string_values = train_data[train_data['ImagePath'] == '']\n",
    "    print(empty_string_values)\n",
    "    return train_data, val_data\n",
    "\n",
    "# Create the generator\n",
    "csv_generator = process_csv_in_chunks(csv_file)\n",
    "\n",
    "# Split the data incrementally\n",
    "train_data, val_data = incremental_train_val_split(csv_generator)\n",
    "\n",
    "exclude_columns = [train_data.columns[22], train_data.columns[23]]  # 'imageName' and 'ImagePath'\n",
    "\n",
    "# Convert paths and labels for compatibility with ImageDataGenerator\n",
    "train_paths = train_data[exclude_columns[1]].values  # The 'ImagePath' column\n",
    "val_paths = val_data[exclude_columns[1]].values  # The 'ImagePath' column\n",
    "\n",
    "train_labels = train_data.drop(columns=['ImageFileName', 'ImagePath']).values\n",
    "val_labels = val_data.drop(columns=['ImageFileName', 'ImagePath']).values\n",
    "\n",
    "# Convert labels to dataframe for compatibility with ImageDataGenerator\n",
    "train_labels_df = pd.DataFrame(train_labels, columns=train_data.columns)\n",
    "val_labels_df = pd.DataFrame(val_labels, columns=val_data.columns)\n",
    "\n",
    "# Create ImageDataGenerators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Combine paths and labels into DataFrames\n",
    "train_df = pd.concat([pd.Series(train_paths, name='ImagePath'), train_labels_df], axis=1)\n",
    "val_df = pd.concat([pd.Series(val_paths, name='ImagePath'), val_labels_df], axis=1)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=image_directory,  # The root directory containing all subdirectories\n",
    "    x_col='ImagePath',\n",
    "    y_col=train_labels_df.columns.tolist(),\n",
    "    target_size=(128, 128),  # Resize images to 128x128\n",
    "    batch_size=32,\n",
    "    class_mode='raw'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory=image_directory,  # The root directory containing all subdirectories\n",
    "    x_col='ImagePath',\n",
    "    y_col=val_labels_df.columns.tolist(),\n",
    "    target_size=(128, 128),  # Resize images to 128x128\n",
    "    batch_size=32,\n",
    "    class_mode='raw'\n",
    ")\n",
    "\n",
    "# Optional: Save the processed data\n",
    "np.save(os.path.join(training_path, 'train_paths.npy'), train_paths)\n",
    "np.save(os.path.join(training_path, 'val_paths.npy'), val_paths)\n",
    "np.save(os.path.join(training_path, 'train_labels.npy'), train_labels)\n",
    "np.save(os.path.join(training_path, 'val_labels.npy'), val_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Build and Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(train_labels_df.shape[1], activation='softmax')  # Use 'sigmoid' for multi-label classification\n",
    "])\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Define Custom Callback for Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeBasedModelCheckpoint(Callback):\n",
    "    def __init__(self, filepath, save_freq='epoch', verbose=0):\n",
    "        super(TimeBasedModelCheckpoint, self).__init__()\n",
    "        self.filepath = filepath\n",
    "        self.save_freq = save_freq\n",
    "        self.verbose = verbose\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.save_freq == 'epoch':\n",
    "            current_time = time.time()\n",
    "            elapsed_time = current_time - self.start_time\n",
    "            # Save every hour (3600 seconds)\n",
    "            if elapsed_time >= 3600:\n",
    "                timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "                save_path = self.filepath.format(epoch=epoch + 1, timestamp=timestamp)\n",
    "                if self.verbose > 0:\n",
    "                    print(f'\\nElapsed time: {elapsed_time:.2f}s - Saving model to {save_path}')\n",
    "                self.model.save(save_path)\n",
    "                self.start_time = time.time()\n",
    "\n",
    "# Path where you want to save your model\n",
    "models_path = os.path.join(base_path,'models')\n",
    "filepath = os.path.join(models_path,'model_epoch{epoch:02d}_time{timestamp}.h5')\n",
    "\n",
    "# Instantiate the custom callback\n",
    "time_based_checkpoint = TimeBasedModelCheckpoint(filepath, save_freq='epoch', verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Setup TensorBoard for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where TensorBoard logs will be saved\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping to avoid unnecessary training\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train the model with the custom callback, TensorBoard, and early stopping\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[time_based_checkpoint, tensorboard_callback, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Launch TensorBoard (Run this cell in a separate code block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure TensorBoard server is started in a terminal\n",
    "# !tensorboard --logdir=logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Make Predictions and Save JSON Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert predictions to JSON\n",
    "def predictions_to_json(predictions, field_names):\n",
    "    results = []\n",
    "    for pred in predictions:\n",
    "        result = {field_names[i]: float(pred[i]) for i in range(len(field_names))}\n",
    "        results.append(result)\n",
    "    return json.dumps(results, indent=4)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(val_generator)\n",
    "field_names = data.columns[1:]  # Exclude 'ImagePath'\n",
    "json_output = predictions_to_json(predictions, field_names)\n",
    "\n",
    "# Save the JSON output\n",
    "with open('predictions.json', 'w') as json_file:\n",
    "    json_file.write(json_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
