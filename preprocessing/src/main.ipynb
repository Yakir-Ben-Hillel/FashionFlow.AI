{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder='D:\\\\'\n",
    "image_dir = os.path.join(root_folder,'new')\n",
    "dataframes_folder=os.path.join(root_folder,'dataframes')\n",
    "images_binary_folder=os.path.join(root_folder,'images_binary')\n",
    "if not os.path.exists(dataframes_folder):\n",
    "    os.mkdir(dataframes_folder)\n",
    "if not os.path.exists(images_binary_folder):\n",
    "    os.mkdir(images_binary_folder)\n",
    "existing_item_ids=[os.path.splitext(filename)[0] for filename in os.listdir(dataframes_folder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging format and level (optional)\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    level=logging.INFO  # Set the logging level (INFO, DEBUG, WARNING, ERROR, CRITICAL)\n",
    ")\n",
    "\n",
    "# Initialize the logger\n",
    "logger = logging.getLogger('my_logger')\n",
    "\n",
    "# Define the file handler to log messages to a file\n",
    "log_file = 'app.log'\n",
    "file_handler = logging.FileHandler(log_file)\n",
    "\n",
    "# Set the logging format for the file handler\n",
    "file_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "file_handler.setFormatter(file_formatter)\n",
    "\n",
    "# Add the file handler to the logger\n",
    "logger.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (224, 224)\n",
    "def load_and_preprocess_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, image_size)\n",
    "    img = img.astype('float32') / 255.0  # Normalize pixel values\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images_save_dataframe(item_id, item_df, image_dir):\n",
    "    binary_item_path = os.path.join(images_binary_folder, str(item_id))\n",
    "    csv_path = os.path.join(dataframes_folder, f'{item_id}.csv')\n",
    "\n",
    "    item_folder = os.path.join(image_dir, str(item_id))\n",
    "    \n",
    "    if os.path.exists(item_folder):\n",
    "        img_files = [f for f in os.listdir(item_folder) if os.path.isfile(os.path.join(item_folder, f))\n",
    "                     and f.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif'))]\n",
    "        \n",
    "        images = []\n",
    "        for img_file in img_files:\n",
    "            img_path = os.path.join(item_folder, img_file)\n",
    "            try:\n",
    "                img_array = load_and_preprocess_image(img_path)\n",
    "                npy_filename = os.path.splitext(img_file)[0] + '.npy'\n",
    "                \n",
    "                if not os.path.exists(binary_item_path):\n",
    "                    os.mkdir(binary_item_path)\n",
    "                    \n",
    "                npy_path = os.path.join(binary_item_path, npy_filename)\n",
    "                np.save(npy_path, img_array)\n",
    "                images.append(npy_path)\n",
    "            except Exception as e:\n",
    "                logger.error(e)\n",
    "        \n",
    "        dfs_list = [pd.concat([pd.DataFrame(row).T]*len(images), ignore_index=True) for _, row in item_df.iterrows()]\n",
    "        \n",
    "        for df, img_path in zip(dfs_list, images * len(item_df)):\n",
    "            df['ImagePath'] = img_path\n",
    "        \n",
    "        final_df = pd.concat(dfs_list, ignore_index=True)\n",
    "        final_df.to_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = (\n",
    "    \"mssql+pyodbc://@DESKTOP-3N7733F\\\\SQLEXPRESS/FashionFlow?trusted_connection=yes&driver=ODBC+Driver+17+for+SQL+Server\"\n",
    ")\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55482\n"
     ]
    }
   ],
   "source": [
    "sql_query = \"\"\"\n",
    "SELECT * FROM ViewFullItem\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and load data into a DataFrame\n",
    "df = pd.read_sql_query(sql_query, engine)\n",
    "df['ImagePath'] = None\n",
    "dfs_dict = dict(tuple(df.groupby('ItemId')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m items \u001b[38;5;241m=\u001b[39m [item \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m dfs_dict\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(item[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m directories]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item_id, item_df \u001b[38;5;129;01min\u001b[39;00m items:\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mprocess_images_save_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 10\u001b[0m, in \u001b[0;36mprocess_images_save_dataframe\u001b[1;34m(item_id, item_df, image_dir)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m      8\u001b[0m item_folder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(image_dir, \u001b[38;5;28mstr\u001b[39m(item_id))\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem_folder\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     11\u001b[0m     img_files \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(item_folder) \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(item_folder, f))\n\u001b[0;32m     12\u001b[0m                  \u001b[38;5;129;01mand\u001b[39;00m f\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.tiff\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.bmp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.gif\u001b[39m\u001b[38;5;124m'\u001b[39m))]\n\u001b[0;32m     14\u001b[0m     images \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "directories=os.listdir(images_binary_folder)\n",
    "items = [item for item in dfs_dict.items() if str(item[0]) not in directories]\n",
    "print(len(items))\n",
    "for item_id, item_df in items:\n",
    "    process_images_save_dataframe(item_id, item_df, image_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "preprocessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
